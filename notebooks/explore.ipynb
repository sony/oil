{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "import pandas as pd\n",
    "import pathlib\n",
    "from definitions import ROOT_DIR\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import QuantileRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%history -f history.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getScore_nips(reward, cpa, cpa_constraint):\n",
    "    beta = 2\n",
    "    penalty = 1\n",
    "    if cpa > cpa_constraint:\n",
    "        coef = cpa_constraint / (cpa + 1e-10)\n",
    "        penalty = pow(coef, beta)\n",
    "    return penalty * reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "period_list = list(range(7, 12))\n",
    "df_list = []\n",
    "for period in period_list:\n",
    "    data_path = ROOT_DIR / \"data\" / \"raw_traffic_parquet\" / f\"period-{period}.parquet\"\n",
    "    df = pd.read_parquet(data_path)\n",
    "    df_list.append(df[df.isExposed == 1])\n",
    "df = pd.concat(df_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exposed_df = df[df[\"isExposed\"] == 1] We already filter exposed data\n",
    "beta_hat = (df.pValue)\n",
    "\n",
    "beta_hat_stoch = beta_hat[df.pValueSigma > 1e-4] / df.pValueSigma[df.pValueSigma > 1e-4]\n",
    "\n",
    "plt.hist(beta_hat[np.abs(beta_hat) < 0.5], bins=100)\n",
    "plt.show()\n",
    "plt.hist(beta_hat[np.abs(beta_hat) > 0.5], bins=100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(beta_hat_stoch[beta_hat_stoch > 0.5], bins=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.hist(df.pValueSigma / df.pValue, bins=100)\n",
    "plt.plot(df.pValue, df.pValueSigma, '.')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pp = np.linspace(np.min(df.pValue), np.max(df.pValue), 50)\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(10, 5))\n",
    "for slot in range(3, 0, -1):\n",
    "    conversion_mean_list = []\n",
    "    pvalue_mean_list = []\n",
    "    count_list = []\n",
    "    slot_df = df[df.adSlot == slot]\n",
    "    for l, r in zip(pp[:-1], pp[1:]):\n",
    "        mask = (slot_df.pValue >= l) & (slot_df.pValue <= r)\n",
    "        conversion_mean_list.append(slot_df.conversionAction[mask].mean())\n",
    "        pvalue_mean_list.append(slot_df.pValue[mask].mean())\n",
    "        count_list.append(mask.sum())\n",
    "    axs[0].plot(pvalue_mean_list, conversion_mean_list, label=slot)\n",
    "    axs[1].plot(pvalue_mean_list, count_list, label=slot)\n",
    "axs[0].plot(pvalue_mean_list, pvalue_mean_list, \"r\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for period in range(7, 28):\n",
    "    print(f\"Period {period}\")\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(10, 5))\n",
    "    period_df = df[df[\"deliveryPeriodIndex\"] == period]\n",
    "    for slot in range(3, 0, -1):\n",
    "        conversion_mean_list = []\n",
    "        pvalue_mean_list = []\n",
    "        count_list = []\n",
    "        slot_df = period_df[period_df.adSlot == slot]\n",
    "        for l, r in zip(pp[:-1], pp[1:]):\n",
    "            mask = (slot_df.pValue >= l) & (slot_df.pValue <= r)\n",
    "            conversion_mean_list.append(slot_df.conversionAction[mask].mean())\n",
    "            pvalue_mean_list.append(slot_df.pValue[mask].mean())\n",
    "            count_list.append(mask.sum())\n",
    "        axs[0].plot(pvalue_mean_list, conversion_mean_list, label=slot)\n",
    "        axs[1].plot(pvalue_mean_list, count_list, label=slot)\n",
    "    axs[0].plot(pvalue_mean_list, pvalue_mean_list, \"r\")\n",
    "    axs[0].set_ylim((0, 0.006))\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import numpy as np\n",
    "\n",
    "# Remove the outliers from the dataset\n",
    "# red_df = df[df.pValue < 4e-3]\n",
    "red_df = df\n",
    "pv = red_df.pValue.to_numpy()\n",
    "pvs = red_df.pValueSigma.to_numpy()\n",
    "\n",
    "X = np.column_stack((pv, pvs, pv * pvs, pv ** 2, pvs ** 2))  # Input features\n",
    "# X = red_df.pValue.to_numpy().reshape(-1, 1)\n",
    "y = red_df.conversionAction.to_numpy()  # Binary outcomes (0 or 1)\n",
    "\n",
    "# Fit logistic regression model\n",
    "# model = LogisticRegression(C=1)\n",
    "model = LinearRegression()\n",
    "model.fit(X, y)\n",
    "\n",
    "# # Predict the probability (beta)\n",
    "# predicted_beta = model.predict_proba(X)[:, 1]  # Probability of conversion (beta)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coef = model.coef_\n",
    "coef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(pv, model.predict(X), \".\")\n",
    "plt.plot(np.linspace(min(pv), max(pv), 10), np.linspace(min(pv), max(pv), 10))\n",
    "# plt.plot(pv, y, '.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import numpy as np\n",
    "\n",
    "# Remove the outliers from the dataset\n",
    "success_df = df[df.conversionAction == 1].reset_index()\n",
    "failure_df = df[df.conversionAction == 0].reset_index()\n",
    "failure_df = failure_df.loc[np.random.choice(failure_df.index, len(success_df), replace=False)]\n",
    "red_df = pd.concat((success_df, failure_df))\n",
    "\n",
    "shuffle_indices = np.random.permutation(len(red_df))\n",
    "X = np.column_stack((red_df.pValue.to_numpy(), red_df.pValueSigma.to_numpy()))  # Input features\n",
    "X = X[shuffle_indices]\n",
    "# X = red_df.pValue.to_numpy().reshape(-1, 1)\n",
    "y = red_df.conversionAction.to_numpy()  # Binary outcomes (0 or 1)\n",
    "y = y[shuffle_indices]\n",
    "\n",
    "# Fit logistic regression model\n",
    "# model = LogisticRegression()\n",
    "model = LinearRegression()\n",
    "model.fit(X, y)\n",
    "\n",
    "# # Predict the probability (beta)\n",
    "# predicted_beta = model.predict_proba(X)[:, 1]  # Probability of conversion (beta)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(success_df.pValue, bins=30, label=\"success\", alpha=0.3)\n",
    "plt.hist(failure_df.pValue, bins=30, label=\"failure\", alpha=0.3)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "success_df = df[df.conversionAction == 1].reset_index()\n",
    "success_df = success_df.loc[np.random.choice(success_df.index, 10000, replace=False)]\n",
    "failure_df = df[df.conversionAction == 0].reset_index()\n",
    "failure_df = failure_df.loc[np.random.choice(failure_df.index, 10000, replace=False)]\n",
    "balanced_df = pd.concat([success_df, failure_df])\n",
    "\n",
    "plt.hist(success_df.pValue, bins=30, alpha=0.5, label=\"success\")\n",
    "plt.hist(failure_df.pValue, bins=30, alpha=0.5, label=\"failure\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "failure_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slot_df = df.groupby(\"adSlot\").mean()\n",
    "slot_df[\"pValueAdjusted\"] = slot_df[\"pValue\"] * slot_df[\"isExposed\"]\n",
    "slot_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seems like all slots are more or less equally effective\n",
    "slot_df.pValue / slot_df.cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slot_df.conversionAction / (slot_df.cost * slot_df.isExposed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slot_df.pValueAdjusted / slot_df.conversionAction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import norm\n",
    "\n",
    "def expected_truncated_gaussian(pvalues, pvalue_sigmas):\n",
    "    # Compute the alpha values\n",
    "    alpha = np.zeros_like(pvalues)\n",
    "    alpha[pvalue_sigmas != 0] = -pvalues[pvalue_sigmas != 0] / pvalue_sigmas[pvalue_sigmas != 0]\n",
    "    \n",
    "    # Compute the PDF and CDF of the standard normal distribution at alpha\n",
    "    phi_alpha = norm.pdf(alpha)\n",
    "    Phi_alpha = norm.cdf(alpha)\n",
    "    \n",
    "    # Compute the expected value for the truncated Gaussian\n",
    "    expected_values = pvalues + pvalue_sigmas * (phi_alpha / (1 - Phi_alpha))\n",
    "    \n",
    "    return expected_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ad_slot in range(1, 4):\n",
    "    pvalue_list = []\n",
    "    conversion_list = []\n",
    "    eff_pvalue_list = []\n",
    "    for period in period_list:\n",
    "        period_df = df[df[\"deliveryPeriodIndex\"] == period]\n",
    "        pvalues = period_df[period_df.adSlot == ad_slot].pValue.to_numpy()\n",
    "        pvalue_sigmas = period_df[period_df.adSlot == ad_slot].pValueSigma.to_numpy()\n",
    "        conversions = period_df[period_df.adSlot == ad_slot].conversionAction.to_numpy()\n",
    "        exposed_frac = period_df[period_df.adSlot == ad_slot].isExposed.to_numpy().mean()\n",
    "        pvalue_list.append(pvalues.mean())\n",
    "        conversion_list.append(conversions.mean())\n",
    "        eff_pvalue_list.append(pvalues.mean() * exposed_frac)\n",
    "    plt.plot(period_list, [p / c for p, c in zip(eff_pvalue_list, conversion_list)])\n",
    "        # exp_vals = expected_truncated_gaussian(pvalues, pvalue_sigmas)\n",
    "        # print(f\"Period {period}, exp_vals: {exp_vals.mean()}, p-values: {pvalues.mean()}, conversions: {conversions.mean()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "advertiser_list = list(range(0, 48))\n",
    "for period in period_list:\n",
    "    period_df = df[df[\"deliveryPeriodIndex\"] == period]\n",
    "    for ad_slot in range(1, 4):\n",
    "        pvalue_list = []\n",
    "        conversion_list = []\n",
    "        eff_pvalue_list = []\n",
    "        for advertiser in advertiser_list:\n",
    "            advertiser_df = period_df[period_df.advertiserNumber == advertiser]\n",
    "            pvalues = advertiser_df[advertiser_df.adSlot == ad_slot].pValue.to_numpy()\n",
    "            pvalue_sigmas = advertiser_df[advertiser_df.adSlot == ad_slot].pValueSigma.to_numpy()\n",
    "            conversions = advertiser_df[advertiser_df.adSlot == ad_slot].conversionAction.to_numpy()\n",
    "            exposed_frac = advertiser_df[advertiser_df.adSlot == ad_slot].isExposed.to_numpy().mean()\n",
    "            pvalue_list.append(pvalues.mean())\n",
    "            conversion_list.append(conversions.mean())\n",
    "            eff_pvalue_list.append(pvalues.mean() * exposed_frac)\n",
    "        plt.plot(advertiser_list, [p / c for p, c in zip(eff_pvalue_list, conversion_list)])\n",
    "    plt.show()\n",
    "        # exp_vals = expected_truncated_gaussian(pvalues, pvalue_sigmas)\n",
    "        # print(f\"Period {period}, exp_vals: {exp_vals.mean()}, p-values: {pvalues.mean()}, conversions: {conversions.mean()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(period_df[period_df.adSlot == 3].conversionAction == 0).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_vals = expected_truncated_gaussian(pvalues, pvalue_sigmas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(exp_als)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All periods pv / E[conv] per slot\n",
    "adSlot\n",
    "0.0         NaN\n",
    "1.0    1.043351\n",
    "2.0    1.037957\n",
    "3.0    1.026732\n",
    "dtype: float32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(\"advertiserNumber\").agg({\n",
    "    \"budget\": [\"mean\", \"min\", \"max\"],\n",
    "    \"CPAConstraint\": [\"mean\", \"min\", \"max\"],\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(\"advertiserNumber\").agg({\n",
    "    \"budget\": [\"mean\", \"min\", \"max\"],\n",
    "    \"CPAConstraint\": [\"mean\", \"min\", \"max\"],\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert all traffic data to parquet\n",
    "first_period = 7\n",
    "last_period = 27\n",
    "for period in range(first_period, last_period + 1):\n",
    "    data_path = ROOT_DIR / \"data\" / \"raw_traffic_final\" / f\"period-{period}.csv\"\n",
    "    print(f\"Loading {data_path}\")\n",
    "    df = pd.read_csv(data_path, dtype=\"float32\")\n",
    "    pathlib.Path(ROOT_DIR / \"data\" / \"raw_traffic_final_parquet\").mkdir(parents=True, exist_ok=True)\n",
    "    out_path = ROOT_DIR / \"data\" / \"raw_traffic_final_parquet\" / f\"period-{period}.parquet\"\n",
    "    print(f\"Saving to {out_path}\")\n",
    "    df.to_parquet(out_path)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Merge all the traffic data into a single dataframe (converted to float32 for memory efficiency)\n",
    "# df_list = []\n",
    "# for period in range(7, 14):\n",
    "#     data_path = ROOT_DIR / \"data\" / \"traffic\" / f\"period-{period}.csv\"\n",
    "#     print(f\"Loading {data_path}\")\n",
    "#     df = pd.read_csv(data_path, dtype=\"float32\")\n",
    "#     df_list.append(df)\n",
    "\n",
    "# # Create a single dataframe\n",
    "# print(\"Concatenating dataframes\")\n",
    "# df = pd.concat(df_list, ignore_index=True).reset_index()\n",
    "# df.drop(columns=[\"index\"], inplace=True)\n",
    "\n",
    "# # Save the dataframe in an efficient format\n",
    "# print(\"Saving dataframe\")\n",
    "# df.to_parquet(ROOT_DIR / \"data\" / \"traffic\" / \"all_periods.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(ROOT_DIR / \"data\" / \"traffic\" / \"training_data_16\" / \"training_data_all-rlData.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "\n",
    "\n",
    "def safe_literal_eval(val):\n",
    "    if pd.isna(val):\n",
    "        return val  # 如果是NaN，返回NaN\n",
    "    try:\n",
    "        return ast.literal_eval(val)\n",
    "    except (ValueError, SyntaxError):\n",
    "        print(ValueError)\n",
    "        return val \n",
    "    \n",
    "safe_literal_eval(df[\"state\"].loc[0]).__len__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all periods df\n",
    "df = pd.read_parquet(ROOT_DIR / \"data\" / \"traffic\" / \"all_periods.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print limits for budget and target cpa\n",
    "budget_limits = (df.budget.min(), df.budget.max())\n",
    "cpa_limits = (df.CPAConstraint.min(), df.CPAConstraint.max())\n",
    "print(\"Budget lim:\", budget_limits, \"CPA lim:\", cpa_limits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the predicted conversion action as product between pValue and isExposed\n",
    "conversion_action_pred = df[\"pValue\"] * df[\"isExposed\"]\n",
    "df[\"conversionAction_pred\"] = conversion_action_pred\n",
    "\n",
    "# Compute cpa\n",
    "cpa_df = df.groupby([\"advertiserNumber\", \"deliveryPeriodIndex\"]\n",
    "                    ).agg({\"cost\": \"sum\",\n",
    "                           \"conversionAction\": \"sum\",\n",
    "                           \"CPAConstraint\": \"mean\",\n",
    "                           \"budget\": \"mean\",\n",
    "                           \"conversionAction_pred\": \"sum\",\n",
    "                           \"advertiserCategoryIndex\": \"mean\",\n",
    "                           \"pValue\": \"mean\"}\n",
    "                          ).reset_index()\n",
    "cpa_df[\"cpa\"] = cpa_df[\"cost\"] / cpa_df[\"conversionAction\"]\n",
    "# cpa_df.set_index(\"advertiserNumber\", inplace=True)\n",
    "cpa_df[\"score\"] = cpa_df.apply(lambda x: getScore_nips(x[\"conversionAction\"], x[\"cpa\"], x[\"CPAConstraint\"]), axis=1)\n",
    "cpa_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot score as a function of budget (the budget per advertiser is constant)\n",
    "fig, ax = plt.subplots()\n",
    "for advertiser in cpa_df[\"advertiserNumber\"].unique():\n",
    "    advertiser_df = cpa_df[cpa_df[\"advertiserNumber\"] == advertiser]\n",
    "    # Plot mean +- std of the score\n",
    "    budget = advertiser_df[\"budget\"].mean()\n",
    "    score = advertiser_df[\"score\"].mean()\n",
    "    std = advertiser_df[\"score\"].std()\n",
    "    ax.errorbar(budget, score, yerr=std, fmt='o', label=f\"Advertiser {advertiser}\")\n",
    "    \n",
    "ax.set_xlabel(\"Budget\")\n",
    "ax.set_ylabel(\"Score\")\n",
    "    # ax.plot(advertiser_df[\"budget\"], advertiser_df[\"score\"], label=f\"Advertiser {advertiser}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit a linear regression to the score as a function of log budget\n",
    "quantile = 0.8\n",
    "X = np.log(cpa_df[\"budget\"]).values.reshape(-1, 1)\n",
    "y = cpa_df[\"score\"].values\n",
    "# reg = LinearRegression(fit_intercept=True).fit(X, y)\n",
    "reg = QuantileRegressor(quantile=quantile, alpha=0).fit(X, y)\n",
    "\n",
    "# Select the elements of cpa_df whose score is larger than the regressed value\n",
    "score_pred = reg.predict(X)\n",
    "budget_filter = cpa_df[\"score\"] > score_pred\n",
    "filter_list.append(budget_filter)\n",
    "print(f\"Fraction of dataset with score > regressed value: {budget_filter.mean()}\")\n",
    "\n",
    "# Plot the linear regression\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "# Sort x and y according to x\n",
    "sort_idx = np.argsort(X, axis=0).flatten()\n",
    "ax.scatter(cpa_df[\"budget\"][budget_filter], cpa_df[\"score\"][budget_filter], color=\"green\", alpha=0.2)\n",
    "ax.scatter(cpa_df[\"budget\"][~budget_filter], cpa_df[\"score\"][~budget_filter], color=\"blue\", alpha=0.2)\n",
    "ax.plot(np.exp(X[sort_idx]), reg.predict(X[sort_idx]), color=\"red\")\n",
    "ax.set_xlabel(\"Budget\")\n",
    "ax.set_ylabel(\"Score\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute median score per CPAConstraint\n",
    "median_score_df = cpa_df.groupby(\"CPAConstraint\").agg({\"score\": lambda x: np.quantile(x, 0.8)})\n",
    "cpa_filter = cpa_df[\"score\"] > median_score_df.loc[cpa_df[\"CPAConstraint\"]].values.flatten()\n",
    "filter_list.append(cpa_filter)\n",
    "\n",
    "# plot score as a function of CPAConstraint\n",
    "x_val = cpa_df[\"CPAConstraint\"]\n",
    "fig, ax = plt.subplots()\n",
    "ax.scatter(x_val[cpa_filter], cpa_df[\"score\"][cpa_filter], color=\"green\", alpha=0.2)\n",
    "ax.scatter(x_val[~cpa_filter], cpa_df[\"score\"][~cpa_filter], color=\"blue\", alpha=0.2)\n",
    "ax.set_xlabel(\"CPAConstraint\")\n",
    "ax.set_ylabel(\"Score\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute median score per CPAConstraint transformed\n",
    "median_score_df = cpa_df.groupby(\"CPAConstraint\").agg({\"score\": lambda x: np.quantile(x, 0.8)})\n",
    "cpa_filter = cpa_df[\"score\"] > median_score_df.loc[cpa_df[\"CPAConstraint\"]].values.flatten()\n",
    "filter_list.append(cpa_filter)\n",
    "\n",
    "# plot score as a function of CPAConstraint\n",
    "x_val = (cpa_df[\"CPAConstraint\"] - 8).abs()\n",
    "fig, ax = plt.subplots()\n",
    "ax.scatter(x_val[cpa_filter], cpa_df[\"score\"][cpa_filter], color=\"green\", alpha=0.2)\n",
    "ax.scatter(x_val[~cpa_filter], cpa_df[\"score\"][~cpa_filter], color=\"blue\", alpha=0.2)\n",
    "ax.set_xlabel(\"CPAConstraint - transformed\")\n",
    "ax.set_ylabel(\"Score\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute median score per advertiser category\n",
    "median_score_df = cpa_df.groupby(\"advertiserCategoryIndex\").agg({\"score\": lambda x: np.quantile(x, 0.9)})\n",
    "category_filter = cpa_df[\"score\"] > median_score_df.loc[cpa_df[\"advertiserCategoryIndex\"]].values.flatten()\n",
    "filter_list.append(category_filter)\n",
    "\n",
    "# Plot score as a function of advertiser category\n",
    "fig, ax = plt.subplots()\n",
    "ax.scatter(cpa_df[\"advertiserCategoryIndex\"][category_filter], cpa_df[\"score\"][category_filter], color=\"green\", alpha=0.2)\n",
    "ax.scatter(cpa_df[\"advertiserCategoryIndex\"][~category_filter], cpa_df[\"score\"][~category_filter], color=\"blue\", alpha=0.2)\n",
    "ax.set_xlabel(\"Advertiser Category\")\n",
    "ax.set_ylabel(\"Score\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute median score per delivery period\n",
    "median_score_df = cpa_df.groupby(\"deliveryPeriodIndex\").agg({\"score\": lambda x: np.quantile(x, 0.9)})\n",
    "period_filter = cpa_df[\"score\"] > median_score_df.loc[cpa_df[\"deliveryPeriodIndex\"]].values.flatten()\n",
    "filter_list.append(period_filter)\n",
    "\n",
    "# Plot score as a function of delivery period\n",
    "fig, ax = plt.subplots()\n",
    "ax.scatter(cpa_df[\"deliveryPeriodIndex\"][period_filter], cpa_df[\"score\"][period_filter], color=\"green\", alpha=0.2)\n",
    "ax.scatter(cpa_df[\"deliveryPeriodIndex\"][~period_filter], cpa_df[\"score\"][~period_filter], color=\"blue\", alpha=0.2)\n",
    "ax.set_xlabel(\"Delivery period\")\n",
    "ax.set_ylabel(\"Score\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute linear regression for the pValue\n",
    "X = cpa_df[\"pValue\"].values.reshape(-1, 1)\n",
    "y = cpa_df[\"score\"].values\n",
    "# reg = LinearRegression(fit_intercept=True).fit(X, y)\n",
    "quantile = 0.8\n",
    "reg = QuantileRegressor(quantile=quantile, alpha=0).fit(X, y)\n",
    "\n",
    "# Select the elements of cpa_df whose score is larger than the regressed value\n",
    "score_pred = reg.predict(X)\n",
    "pValue_filter = cpa_df[\"score\"] > score_pred\n",
    "filter_list.append(pValue_filter)\n",
    "\n",
    "# Plot the linear regression\n",
    "fig, ax = plt.subplots()\n",
    "sort_idx = np.argsort(X, axis=0).flatten()\n",
    "ax.scatter(cpa_df[\"pValue\"][pValue_filter], cpa_df[\"score\"][pValue_filter], color=\"green\", alpha=0.2)\n",
    "ax.scatter(cpa_df[\"pValue\"][~pValue_filter], cpa_df[\"score\"][~pValue_filter], color=\"blue\", alpha=0.2)\n",
    "ax.plot(X[sort_idx], reg.predict(X[sort_idx]), color=\"red\")\n",
    "ax.set_xlabel(\"pValue\")\n",
    "ax.set_ylabel(\"Score\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# from sklearn.ensemble import RandomForestRegressor\n",
    "# from sklearn.model_selection import KFold\n",
    "# from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# # Assuming your dataset is loaded into a DataFrame called df\n",
    "# # and the features and target columns are specified as below\n",
    "# features = [\"deliveryPeriodIndex\", \"advertiserCategoryIndex\", \"pValue\", \"budget\", \"CPAConstraint\"]\n",
    "# target = \"score\"\n",
    "\n",
    "# # Separate the features (X) and target (y)\n",
    "# X = cpa_df[features]\n",
    "# y = cpa_df[target]\n",
    "\n",
    "# # Initialize the RandomForestRegressor\n",
    "# model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "\n",
    "# # Initialize KFold with 10 splits\n",
    "# kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "# # To store actual and predicted values\n",
    "# actual_scores = []\n",
    "# predicted_scores = []\n",
    "\n",
    "# # To store feature importances\n",
    "# feature_importances = np.zeros(len(features))\n",
    "\n",
    "# # Perform 10-fold cross-validation\n",
    "# for train_index, test_index in kf.split(X):\n",
    "#     # Split the data into train and test sets\n",
    "#     X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "#     y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    \n",
    "#     # Train the model on the training set\n",
    "#     model.fit(X_train, y_train)\n",
    "    \n",
    "#     # Predict the score for the test set\n",
    "#     y_pred = model.predict(X_test)\n",
    "    \n",
    "#     # Store actual and predicted values\n",
    "#     actual_scores.extend(y_test)\n",
    "#     predicted_scores.extend(y_pred)\n",
    "\n",
    "#     # Accumulate feature importances\n",
    "#     feature_importances += model.feature_importances_\n",
    "\n",
    "# # Average the feature importances over all folds\n",
    "# feature_importances /= kf.get_n_splits()\n",
    "\n",
    "\n",
    "# # Convert the results to a DataFrame for easier analysis\n",
    "# results_df = pd.DataFrame({\n",
    "#     \"actual_score\": actual_scores,\n",
    "#     \"predicted_score\": predicted_scores\n",
    "# })\n",
    "\n",
    "# # Calculate the overall mean squared error\n",
    "# mse = mean_squared_error(results_df[\"actual_score\"], results_df[\"predicted_score\"])\n",
    "# print(f\"Mean Squared Error: {mse}\")\n",
    "\n",
    "# # Optionally, you can now identify successful campaigns\n",
    "# # For example, by checking where actual_score > predicted_score\n",
    "# alpha = 1.3\n",
    "# results_df[\"successful_campaign\"] = results_df[\"actual_score\"] > alpha * results_df[\"predicted_score\"]\n",
    "\n",
    "# print(results_df[\"successful_campaign\"].mean())\n",
    "\n",
    "# # Feature Importance\n",
    "# importance_df = pd.DataFrame({\n",
    "#     'feature': features,\n",
    "#     'importance': feature_importances\n",
    "# })\n",
    "\n",
    "# # Sort by importance\n",
    "# importance_df = importance_df.sort_values(by='importance', ascending=False)\n",
    "\n",
    "# print(\"Feature Importances:\")\n",
    "# print(importance_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Assuming your dataset is loaded into a DataFrame called df\n",
    "# # and the features and target columns are specified as below\n",
    "# features = [\"deliveryPeriodIndex\", \"advertiserCategoryIndex\", \"pValue\", \"budget\", \"CPAConstraint\"]\n",
    "# target = \"score\"\n",
    "\n",
    "# # Separate the features (X) and target (y)\n",
    "# X = cpa_df[features]\n",
    "# y = cpa_df[target]\n",
    "\n",
    "# # Initialize the QuantileRegressor\n",
    "# model = QuantileRegressor(quantile=0.7, alpha=0)\n",
    "\n",
    "# # Initialize KFold with 10 splits\n",
    "# kf = KFold(n_splits=50, shuffle=True, random_state=42)\n",
    "\n",
    "# # To store actual and predicted values\n",
    "# actual_scores = []\n",
    "# predicted_scores = []\n",
    "\n",
    "# # Perform 10-fold cross-validation\n",
    "# for train_index, test_index in kf.split(X):\n",
    "#     # Split the data into train and test sets\n",
    "#     X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "#     y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    \n",
    "#     # Train the model on the training set\n",
    "#     model.fit(X_train, y_train)\n",
    "    \n",
    "#     # Predict the score for the test set\n",
    "#     y_pred = model.predict(X_test)\n",
    "    \n",
    "#     # Store actual and predicted values\n",
    "#     actual_scores.extend(y_test)\n",
    "#     predicted_scores.extend(y_pred)\n",
    "\n",
    "\n",
    "# # Convert the results to a DataFrame for easier analysis\n",
    "# results_df = pd.DataFrame({\n",
    "#     \"actual_score\": actual_scores,\n",
    "#     \"predicted_score\": predicted_scores\n",
    "# })\n",
    "\n",
    "# # Calculate the overall mean squared error\n",
    "# mse = mean_squared_error(results_df[\"actual_score\"], results_df[\"predicted_score\"])\n",
    "# print(f\"Mean Squared Error: {mse}\")\n",
    "\n",
    "# # Optionally, you can now identify successful campaigns\n",
    "# # For example, by checking where actual_score > predicted_score\n",
    "# alpha = 1\n",
    "# results_df[\"successful_campaign\"] = results_df[\"actual_score\"] > alpha * results_df[\"predicted_score\"]\n",
    "\n",
    "# print(results_df[\"successful_campaign\"].mean())\n",
    "\n",
    "# # # Feature Importance\n",
    "# # importance_df = pd.DataFrame({\n",
    "# #     'feature': features,\n",
    "# #     'importance': feature_importances\n",
    "# # })\n",
    "\n",
    "# # # Sort by importance\n",
    "# # importance_df = importance_df.sort_values(by='importance', ascending=False)\n",
    "\n",
    "# # print(\"Feature Importances:\")\n",
    "# # print(importance_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_filter = np.any(filter_list, axis=0)\n",
    "print(f\"Fraction of dataset kept: {final_filter.mean()}\")\n",
    "# final_filter = results_df[\"successful_campaign\"]\n",
    "\n",
    "# Fit a linear regression to the score as a function of log budget\n",
    "X = np.log(cpa_df[\"budget\"]).values.reshape(-1, 1)\n",
    "y = cpa_df[\"score\"].values\n",
    "reg = LinearRegression(fit_intercept=True).fit(X, y)\n",
    "\n",
    "# Plot the linear regress\n",
    "# \n",
    "# ion\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "# Sort x and y according to x\n",
    "sort_idx = np.argsort(X, axis=0).flatten()\n",
    "ax.scatter(cpa_df[\"budget\"][~final_filter], cpa_df[\"score\"][~final_filter], color=\"blue\", alpha=0.2)\n",
    "ax.scatter(cpa_df[\"budget\"][final_filter], cpa_df[\"score\"][final_filter], color=\"green\", alpha=0.5)\n",
    "ax.plot(np.exp(X[sort_idx]), reg.predict(X[sort_idx]), color=\"red\")\n",
    "ax.set_xlabel(\"Budget\")\n",
    "ax.set_ylabel(\"Score\")\n",
    "fig.show()\n",
    "\n",
    "\n",
    "# plot score as a function of CPAConstraint\n",
    "fig, ax = plt.subplots()\n",
    "ax.scatter(cpa_df[\"CPAConstraint\"][~final_filter], cpa_df[\"score\"][~final_filter], color=\"blue\", alpha=0.2)\n",
    "ax.scatter(cpa_df[\"CPAConstraint\"][final_filter], cpa_df[\"score\"][final_filter], color=\"green\", alpha=0.5)\n",
    "ax.set_xlabel(\"CPAConstraint\")\n",
    "ax.set_ylabel(\"Score\")\n",
    "fig.show()\n",
    "\n",
    "\n",
    "# Plot score as a function of advertiser category\n",
    "fig, ax = plt.subplots()\n",
    "ax.scatter(cpa_df[\"advertiserCategoryIndex\"][~final_filter], cpa_df[\"score\"][~final_filter], color=\"blue\", alpha=0.2)\n",
    "ax.scatter(cpa_df[\"advertiserCategoryIndex\"][final_filter], cpa_df[\"score\"][final_filter], color=\"green\", alpha=0.5)\n",
    "ax.set_xlabel(\"Advertiser Category\")\n",
    "ax.set_ylabel(\"Score\")\n",
    "fig.show()\n",
    "\n",
    "# Compute linear regression for the pValue\n",
    "X = cpa_df[\"pValue\"].values.reshape(-1, 1)\n",
    "y = cpa_df[\"score\"].values\n",
    "reg = LinearRegression(fit_intercept=True).fit(X, y)\n",
    "\n",
    "# Plot the linear regression\n",
    "fig, ax = plt.subplots()\n",
    "sort_idx = np.argsort(X, axis=0).flatten()\n",
    "ax.scatter(cpa_df[\"pValue\"][~final_filter], cpa_df[\"score\"][~final_filter], color=\"blue\", alpha=0.2)\n",
    "ax.scatter(cpa_df[\"pValue\"][final_filter], cpa_df[\"score\"][final_filter], color=\"green\", alpha=0.5)\n",
    "ax.plot(X[sort_idx], reg.predict(X[sort_idx]), color=\"red\")\n",
    "ax.set_xlabel(\"pValue\")\n",
    "ax.set_ylabel(\"Score\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the initial dataframe according to the final filter\n",
    "filtered_cpa_df = cpa_df[final_filter]\n",
    "\n",
    "# Select in the original df the campaigns where the couple (advertiserNumber, deliveryPeriodIndex) is in the filtered cpa_df\n",
    "df_list = []\n",
    "for adn, dp in zip(filtered_cpa_df[\"advertiserNumber\"], filtered_cpa_df[\"deliveryPeriodIndex\"]):\n",
    "    print(adn, dp)\n",
    "    df_list.append(df[(df[\"advertiserNumber\"] == adn) & (df[\"deliveryPeriodIndex\"] == dp)])\n",
    "top_campaign_df = pd.concat(df_list)\n",
    "# df_filter = df[[\"advertiserNumber\", \"deliveryPeriodIndex\"]].apply(lambda x: (x[\"advertiserNumber\"], x[\"deliveryPeriodIndex\"]) in zip(filtered_cpa_df[\"advertiserNumber\"], filtered_cpa_df[\"deliveryPeriodIndex\"]), axis=1)\n",
    "# top_campaign_df = df[df_filter]\n",
    "\n",
    "print(top_campaign_df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the filtered dataframe\n",
    "out_path = ROOT_DIR / \"data\" / \"traffic\" / \"top_campaigns_quantile.parquet\"\n",
    "top_campaign_df.to_parquet(out_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "alibaba",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
