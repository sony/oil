{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from definitions import ROOT_DIR\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.interpolate import griddata\n",
    "import plotly.graph_objs as go\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_dir = ROOT_DIR / \"output\" / \"offline_evaluation\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_results(experiment_name, fig=None, cmap='Viridis', name=\"Heuristic\", opacity=0.6):\n",
    "    result_path = eval_dir / f\"{experiment_name}.json\"\n",
    "    with open(result_path, \"r\") as f:\n",
    "        data = json.load(f)\n",
    "    scores = np.array([item['score'] for item in data])\n",
    "    cpa_constraints = np.array([item['cpa_constraint'] for item in data])\n",
    "    budgets = np.array([item['budget'] for item in data])\n",
    "    \n",
    "    # Create grid and interpolate\n",
    "    grid_x, grid_y = np.mgrid[min(cpa_constraints):max(cpa_constraints):100j,\n",
    "                            min(budgets):max(budgets):100j]\n",
    "    grid_z = griddata((cpa_constraints, budgets), scores, (grid_x, grid_y), method='cubic')\n",
    "\n",
    "    if fig is None:\n",
    "        fig = go.Figure(data=[go.Surface(z=grid_z, x=grid_x, y=grid_y, colorscale=cmap, opacity=opacity,\n",
    "                        colorbar=dict(title=name, len=0.5, y=0.25))])\n",
    "        fig.update_layout(scene = dict(\n",
    "                        xaxis_title='CPA Constraint',\n",
    "                        yaxis_title='Budget',\n",
    "                        zaxis_title='Score'),\n",
    "                    width=700,\n",
    "                    margin=dict(r=20, b=10, l=10, t=10))\n",
    "    else:\n",
    "        fig.add_trace(go.Surface(z=grid_z, x=grid_x, y=grid_y, colorscale=cmap, opacity=opacity,\n",
    "                      colorbar=dict(title=name, len=0.5, y=0.75)))\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all the evaluations from one experiment and plot the means\n",
    "# experiment_name = \"IQL/train_quantile_16_002\"\n",
    "experiment_name = \"BC/027_train_full_dataset_29\"\n",
    "# experiment_name = \"IQL/train_full_dataset_16_001\"\n",
    "experiment_dir = eval_dir / experiment_name\n",
    "\n",
    "# Iterate through all the json files inthe directory\n",
    "checkpoint_paths = list(experiment_dir.glob(\"*.json\"))\n",
    "\n",
    "def get_number(checkpoint_path):\n",
    "    return int(checkpoint_path.stem.split(\"_\")[-1])\n",
    "\n",
    "sorted_checkpoints = sorted(checkpoint_paths, key=get_number)\n",
    "mean_score_list = []\n",
    "for path in sorted_checkpoints:\n",
    "    result = json.load(open(path, \"r\"))\n",
    "    score_list = [item['score'] for item in result]\n",
    "    mean_score_list.append(np.mean(score_list))\n",
    "\n",
    "plt.plot([get_number(c) for c in sorted_checkpoints], mean_score_list)\n",
    "\n",
    "# Get the best checkpoint\n",
    "best_checkpoint = sorted_checkpoints[np.argmax(mean_score_list)]\n",
    "print(best_checkpoint, np.max(mean_score_list))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opacity = 1\n",
    "algo = \"PPO\"\n",
    "\n",
    "# checkpoint = 19000\n",
    "# print(f\"Checkpoint: {checkpoint}\")\n",
    "# experiment_name = f\"BC/train_whole_dataset_29_017/checkpoint_{checkpoint}\"  # \"onlineLpTest\"  # BC_train_004_checkpoint_190000\n",
    "# experiment_name = f\"BC/train_full_dataset_16_023/checkpoint_{checkpoint}\"  # \"onlineLpTest\"  # BC_train_004_checkpoint_190000\n",
    "# experiment_name = f\"BC/train_top_quantile_16_024/checkpoint_4000\"  # good, aslo 5000\n",
    "# experiment_name = f\"IQL/train_full_dataset_16_001/checkpoint_21000\"  # good\n",
    "# experiment_name = f\"IQL/train_regression_16_003/checkpoint_36000\"  # good\n",
    "# experiment_name = f\"BC/027_train_full_dataset_29/checkpoint_3000\"  # good\n",
    "experiment_name = f\"PPO/033_ppo_seed_0_dense_base_ranges_29_obs_exp_multi_action/checkpoint_3500000\"\n",
    "# experiment_name = f\"PPO/029_ppo_seed_0_dense_base_ranges_29_obs_exp_single_action_simplified/checkpoint_10750000\"  # best, 0.41\n",
    "# experiment_name = f\"PPO/031_ppo_seed_0_dense_base_ranges_19_obs_exp_multi_action_simplified/checkpoint_8000000\"  # best, 0.41\n",
    "# experiment_name = f\"BC/train_top_regression_16_025/checkpoint_{checkpoint}\"  # good 16000, 19000 current best at 0.39\n",
    "fig = plot_results(experiment_name, cmap=\"Blues_r\", name=\"Competitor\", opacity=opacity)\n",
    "\n",
    "# experiment_name = \"onlineLpTest/onlineLpTest/checkpoint_\"  # \"heuristic\"  \n",
    "experiment_name = f\"BC/train_top_regression_16_025/checkpoint_19000\" # best\n",
    "# experiment_name = f\"IQL/train_regression_16_002/checkpoint_9000\"  # good\n",
    "\n",
    "fig = plot_results(experiment_name, fig=fig, cmap='Reds', name=\"Sota\", opacity=opacity)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# experiment_name = \"BC_train_004_checkpoint_27000\"  # best so far?\n",
    "for idx in range(1, 5):\n",
    "    checkpoint = int(idx * 1000)\n",
    "    print(f\"Checkpoint: {checkpoint}\")\n",
    "    experiment_name = f\"IQL_train_regression_001_checkpoint_{checkpoint}\"  # \"onlineLpTest\"  # BC_train_004_checkpoint_190000\n",
    "    fig = plot_results(experiment_name, cmap=\"Turbo_r\", name=\"IQL\")\n",
    "    experiment_name = \"onlineLpTest\"  # \"onlineLpTest\"  # BC_train_004_checkpoint_190000\n",
    "    fig = plot_results(experiment_name, fig=fig, cmap='Inferno', name=\"Heuristic\")\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "result_path = eval_dir / f\"{experiment_name}.json\"\n",
    "with open(result_path, \"r\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "scores = np.array([item['score'] for item in data])\n",
    "cpa_constraints = np.array([item['cpa_constraint'] for item in data])\n",
    "budgets = np.array([item['budget'] for item in data])\n",
    "\n",
    "# Create grid and interpolate\n",
    "grid_x, grid_y = np.mgrid[min(cpa_constraints):max(cpa_constraints):100j,\n",
    "                          min(budgets):max(budgets):100j]\n",
    "grid_z = griddata((cpa_constraints, budgets), scores, (grid_x, grid_y), method='cubic')\n",
    "\n",
    "# Plotly surface plot\n",
    "fig = go.Figure(data=[go.Surface(z=grid_z, x=grid_x, y=grid_y, colorscale='Viridis')])\n",
    "\n",
    "# Set the axes ranges explicitly if needed\n",
    "fig.update_layout(scene = dict(\n",
    "                    xaxis=dict(range=[min(cpa_constraints), max(cpa_constraints)], title='CPA Constraint'),\n",
    "                    yaxis=dict(range=[min(budgets), max(budgets)], title='Budget'),\n",
    "                    zaxis=dict(title='Score')),\n",
    "                  width=700,\n",
    "                  margin=dict(r=20, b=10, l=10, t=10))\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objs as go\n",
    "import numpy as np\n",
    "\n",
    "# # Generate some example data\n",
    "# x = np.linspace(-5, 5, 100)\n",
    "# y = np.linspace(-5, 5, 100)\n",
    "# x, y = np.meshgrid(x, y)\n",
    "# z = np.sin(np.sqrt(x**2 + y**2))\n",
    "\n",
    "# Create the surface plot\n",
    "fig = go.Figure(data=[go.Surface(z=grid_z, x=grid_x, y=grid_y, colorscale='Viridis')])\n",
    "\n",
    "# Update layout to include axis labels\n",
    "fig.update_layout(scene=dict(\n",
    "                    xaxis_title='X Axis',\n",
    "                    yaxis_title='Y Axis',\n",
    "                    zaxis_title='Z Axis'),\n",
    "                  width=700,\n",
    "                  margin=dict(r=20, b=10, l=10, t=10))\n",
    "\n",
    "# Show the plot\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_name = \"BC_train_004_checkpoint_100000\"  # \"onlineLpTest\"  # BC_train_004_checkpoint_190000\n",
    "plot_results(experiment_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_name = \"BC_train_004_checkpoint_190000\"  # \"onlineLpTest\"  # BC_train_004_checkpoint_190000\n",
    "plot_results(experiment_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_name = \"onlineLpTest\"  # \"onlineLpTest\"  # BC_train_004_checkpoint_190000\n",
    "plot_results(experiment_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "alibaba",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
